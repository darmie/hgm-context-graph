---
marp: true
theme: default
paginate: true
size: 4:3
backgroundColor: #ffffff
color: #2d1b4e
style: |
  section {
    background-color: #ffffff;
    color: #2d1b4e;
    font-family: 'Segoe UI', Arial, sans-serif;
    font-size: 24px;
    padding: 25px 40px;
  }
  h1, h2, h3 {
    color: #6b21a8;
    margin-top: 0.3em;
    margin-bottom: 0.3em;
  }
  h1 {
    font-size: 1.6em;
    border-bottom: 3px solid #6b21a8;
    padding-bottom: 0.15em;
  }
  h2 {
    font-size: 1.3em;
  }
  pre {
    font-size: 0.75em;
    line-height: 1.2;
    margin: 0.3em 0;
  }
  code {
    background-color: #f3e8ff;
    color: #581c87;
    padding: 1px 4px;
    border-radius: 3px;
  }
  pre {
    background-color: #faf5ff;
    border-left: 3px solid #6b21a8;
    padding: 0.5em 0.8em;
  }
  pre code {
    background-color: transparent;
  }
  table {
    font-size: 0.8em;
    margin: 0.3em 0;
  }
  th {
    background-color: #6b21a8;
    color: white;
    padding: 4px 8px;
  }
  td {
    border-color: #e9d5ff;
    padding: 3px 8px;
  }
  blockquote {
    border-left: 3px solid #a855f7;
    background-color: #faf5ff;
    padding: 0.3em 0.8em;
    font-style: italic;
    margin: 0.3em 0;
  }
  p {
    margin: 0.4em 0;
  }
  ul, ol {
    margin: 0.3em 0;
    padding-left: 1.2em;
  }
  li {
    margin: 0.15em 0;
  }
  .purple-bg {
    background-color: #6b21a8;
    color: white;
  }
  .purple-bg h1, .purple-bg h2, .purple-bg h3, .purple-bg p, .purple-bg strong, .purple-bg p strong {
    color: white !important;
    border-bottom-color: white;
  }
  .purple-bg * {
    color: white !important;
  }
  a {
    color: #7c3aed;
  }
  strong {
    color: #6b21a8;
  }
  .columns {
    display: grid;
    grid-template-columns: 1fr 1fr;
    gap: 0.8em;
  }
---

<!-- _class: purple-bg -->
<!-- _backgroundColor: #6b21a8 -->
<!-- _color: #ffffff -->
<style scoped>
h1, h2, p, strong, a { color: #ffffff !important; }
h1 { border-bottom-color: #ffffff; }
</style>

# Hierarchical Context Graph Systems

## Building Cognitive Memory for AI Agents

**Context Engineering | Agent State | Agentic RAG | Memory Systems**

**Damilare Akinlaja**
<img src="https://cdn.simpleicons.org/github/white" width="20" height="20" style="vertical-align: middle;" /> [github.com/darmie](https://github.com/darmie) | <img src="https://cdn.simpleicons.org/x/white" width="18" height="18" style="vertical-align: middle;" /> [x.com/fourEyedWiz](https://x.com/fourEyedWiz)

---

# Why Learn Context Engineering?

| Aspect | Details |
|--------|---------|
| **Field** | AI/ML Engineering, LLM Application Development |
| **Application Areas** | Chatbots, AI Assistants, Knowledge Management, RAG Systems |
| **Industry Usage** | Tech, Finance, Healthcare, Legal, Customer Service |
| **Career Impact** | High-demand skill for AI Engineers, 40%+ salary premium |

**Who's Hiring**: OpenAI, Anthropic, Google, Microsoft, Amazon, startups building AI products

---

# Prerequisites & Target Audience

**Target Audience:**
- Software engineers building AI-powered applications
- ML engineers working with LLMs
- Technical leads designing agent architectures

**Prerequisites:**
- Basic Python programming
- Understanding of LLMs and embeddings
- Familiarity with vector databases (helpful, not required)

**Pre-Reading:**
- [Attention Is All You Need](https://arxiv.org/abs/1706.03762) - Transformer basics
- [RAG Survey](https://arxiv.org/abs/2312.10997) - Retrieval-Augmented Generation overview

---

# Workshop Agenda

1. **Context Engineering Landscape** - Where HGM fits
2. **Memory Types** - Cognitive foundations
3. **Agent State Management** - Focus & episodes
4. **Temperature Scoring** - Multi-factor relevance
5. **Three-Tier Memory** - Hot/Warm/Cold architecture
6. **Agentic RAG** - Active recall with promotion
7. **Pattern Graph** - Learned response strategies
8. **LLM Orchestration** - Intelligent decision-making
9. **Hands-on Exercises & Quizzes**

---

# What is Context Engineering?

> "Context engineering is the new prompt engineering"
> â€” Andrej Karpathy

**The discipline of managing what information flows into an LLM's context window.**

| Challenge | Impact | Reference |
|-----------|--------|-----------|
| Limited context (4K-200K tokens) | Can't include everything | [MemGPT](https://arxiv.org/abs/2310.08560) |
| Token cost | More tokens = more $ | [RAG Survey](https://arxiv.org/abs/2312.10997) |
| Relevance matters | Irrelevant context = poor answers | [Generative Agents](https://arxiv.org/abs/2304.03442) |
| Static retrieval fails | Same docs regardless of context | [ACE](https://arxiv.org/abs/2510.04618) |

---

# The Evolution of Context Management

```
Prompt Engineering â†’ RAG v1 â†’ RAG v2 â†’ Agentic RAG â†’ Context Engineering
     (static)        (retrieve)  (chunk)   (active)      (holistic)
                                              â†‘
                                         HGM operates here
```

**Key insight**: Traditional RAG is **passive**. HGM is **active**â€”it reorganizes memories based on what's relevant NOW.

---

# Research Foundations

| Paper | Key Contribution | Link |
|-------|------------------|------|
| **Generative Agents** | Memory streams, recency Ã— importance Ã— relevance | [arXiv](https://arxiv.org/abs/2304.03442) |
| **MemGPT** | Virtual context management, paging | [arXiv](https://arxiv.org/abs/2310.08560) |
| **Reflexion** | Learning from failures | [arXiv](https://arxiv.org/abs/2303.11366) |
| **RAPTOR** | Recursive summarization trees | [arXiv](https://arxiv.org/abs/2401.18059) |
| **ACE** | Evolving context playbooks, self-improving agents | [arXiv](https://arxiv.org/abs/2510.04618) |
| **ACT-R / SOAR** | Cognitive architectures | â€” |

HGM synthesizes these ideas into a unified system.

---

<!-- _class: purple-bg -->
<!-- _backgroundColor: #6b21a8 -->
<!-- _color: #ffffff -->
<style scoped>
h1, h2, p, strong { color: #ffffff !important; }
h1 { border-bottom-color: #ffffff; }
</style>

# Section 1
## Memory Types

---

# Four Memory Types (Cognitive Science)

| Type | What It Stores | Example |
|------|----------------|---------|
| **SEMANTIC** | Facts, concepts, knowledge | "Python is dynamically typed" |
| **EPISODIC** | Events, experiences | "We discussed auth yesterday" |
| **PROCEDURAL** | Instructions, how-to | "To deploy: docker compose up" |
| **EMOTIONAL** | Preferences, sentiment | "User prefers concise answers" |

Based on **Tulving's memory taxonomy** from cognitive psychology.

---

# Memory Types in Code

```python
class MemoryType(str, Enum):
    SEMANTIC = "semantic"      # Facts, concepts
    EPISODIC = "episodic"      # Events, experiences
    PROCEDURAL = "procedural"  # Instructions, how-to
    EMOTIONAL = "emotional"    # Preferences, sentiment

@dataclass
class Memory:
    id: str
    content: str
    embedding: np.ndarray
    memory_type: MemoryType
    temperature: float  # 0.0 to 1.0
```

---

# Why Memory Types Matter

**Without classification:**
- Facts and preferences treated identically
- Instructions buried in noise
- Can't prioritize by query intent

**With classification:**
- "How to deploy?" â†’ Prioritize PROCEDURAL
- "What happened yesterday?" â†’ Prioritize EPISODIC
- "User preferences?" â†’ Prioritize EMOTIONAL

---

<!-- _class: purple-bg -->
<!-- _backgroundColor: #6b21a8 -->
<!-- _color: #ffffff -->
<style scoped>
h1, h2, p, strong { color: #ffffff !important; }
h1 { border-bottom-color: #ffffff; }
</style>

# Section 2
## Agent State Management

---

# Agent Context Components

```python
@dataclass
class AgentContext:
    agent_id: str
    agent_role: str  # "researcher", "coder", etc.

    # Focus tracking
    focus_embedding: np.ndarray  # What agent is "thinking about"
    focus_entities: set[str]      # Key concepts
    focus_hierarchy_path: str     # "tech/python/async"

    # Session tracking
    turn_count: int
    current_episode: Episode
```

**Focus** determines which memories are relevant RIGHT NOW.

---

# Episode Management

**Episodes** = Coherent conversation segments grouped by topic

```
Session Start
    â”‚
    â”œâ”€â”€ Episode 1: "Debugging auth" â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   â””â”€â”€ Memories about auth, JWT, login         â”‚
    â”‚                                               â”‚ Topic drift
    â”œâ”€â”€ Episode 2: "Deployment planning" â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ detected!
    â”‚   â””â”€â”€ Memories about Docker, CI/CD           â”‚
    â”‚                                               â”‚
    â””â”€â”€ Episode 3: "Code review" â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Detecting topic changes helps archive context and reset focus.

---

<!-- _class: purple-bg -->
<!-- _backgroundColor: #6b21a8 -->
<!-- _color: #ffffff -->
<style scoped>
h1, h2, p, strong { color: #ffffff !important; }
h1 { border-bottom-color: #ffffff; }
</style>

# Section 3
## Temperature Scoring

---

# What is Temperature?

A **unified metric (0.0 to 1.0)** representing how "hot" a memory is RIGHT NOW.

| Zone | Range | Meaning |
|------|-------|---------|
| ğŸ”¥ BLAZING | >0.85 | Critical for current task |
| ğŸŒ¡ï¸ HOT | 0.70-0.85 | Working memory |
| â˜€ï¸ WARM | 0.50-0.70 | Session cache |
| ğŸŒ¤ï¸ COOLING | 0.30-0.50 | Fading relevance |
| â„ï¸ COLD | <0.30 | Long-term archive |

---

# Temperature Formula

```
temperature = 0.30 Ã— recency
            + 0.15 Ã— frequency
            + 0.35 Ã— relevance
            + 0.15 Ã— entity_overlap
            + 0.05 Ã— agent_match
```

| Factor | Weight | Calculation |
|--------|--------|-------------|
| Recency | 30% | `0.5^(hours_ago / 24)` |
| Frequency | 15% | `access_count / max_count` |
| Relevance | 35% | Cosine similarity to focus |
| Entity overlap | 15% | Keyword intersection |
| Agent match | 5% | Same agent bonus |

---

# Why Multi-Factor Scoring?

**Single-factor approaches fail:**

| Approach | Problem |
|----------|---------|
| Most recent only | Misses relevant older knowledge |
| Most accessed only | Ignores current context |
| Similarity only | Misses entity connections |

**Temperature combines all signals:**
- Recent + relevant + accessed = ğŸ”¥ BLAZING
- Old but highly relevant = Still promoted
- Recent but irrelevant = Cools quickly

---

<!-- _class: purple-bg -->
<!-- _backgroundColor: #6b21a8 -->
<!-- _color: #ffffff -->
<style scoped>
h1, h2, p, strong { color: #ffffff !important; }
h1 { border-bottom-color: #ffffff; }
</style>

# Section 4
## Three-Tier Memory Architecture

---

# The Three Tiers

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       HOT TIER          â”‚  â† <1ms (Rust in-memory)
â”‚     Working Memory      â”‚     Token-budget LRU eviction
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†‘ promote â”‚ demote â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       WARM TIER         â”‚  â† <50ms (Redis)
â”‚     Session Cache       â”‚     Recent interactions
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†‘ promote â”‚ demote â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       COLD TIER         â”‚  â† <200ms (PostgreSQL)
â”‚    Long-term Storage    â”‚     Full knowledge base
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Hot Tier Deep Dive

**Purpose**: Sub-millisecond access to most critical memories

**Key features**:
- **Token-budget eviction** (not count-based)
- **LRU policy** for cache management
- **Vectorized similarity** (SIMD acceleration)
- **Entity boost** for keyword matches

```python
class HotTier:
    max_tokens: int = 8000  # Context budget

    def scan(self, query_embedding, focus_entities, limit=10):
        # Batch cosine similarity (vectorized)
        similarities = (embeddings / norms) @ query_vector
```

---

# Tier Movement Rules

| Current | Temperature | Action |
|---------|-------------|--------|
| Cold | â‰¥ 0.70 | **Promote to Hot** |
| Cold | â‰¥ 0.50 | Promote to Warm |
| Warm | â‰¥ 0.70 | **Promote to Hot** |
| Warm | < 0.50 | Demote to Cold |
| Hot | < 0.50 | **Demote to Warm** |

**Automatic organization** based on access patterns!

---

<!-- _class: purple-bg -->
<!-- _backgroundColor: #6b21a8 -->
<!-- _color: #ffffff -->
<style scoped>
h1, h2, p, strong { color: #ffffff !important; }
h1 { border-bottom-color: #ffffff; }
</style>

# Section 5
## Agentic RAG

---

# Traditional RAG vs Agentic RAG

| Traditional RAG | Agentic RAG (HGM) |
|-----------------|-------------------|
| Search once, return results | Search + reorganize |
| All memories equally accessible | Hot = fast, Cold = slower |
| No learning from patterns | Promotes frequently used |
| Cold start every query | Warmed-up context |
| Static indexes | Self-organizing tiers |

---

# Active Recall Flow

```python
def recall(query, focus_entities):
    # 1. Search all tiers in parallel
    hot_results = hot_tier.scan(query_emb)
    warm_results = warm_tier.search(query_emb)
    cold_results = cold_tier.search(query_emb)

    # 2. Score with temperature formula
    for memory in all_results:
        memory.temperature = compute_temperature(memory, focus)

    # 3. Promote/demote based on new temperatures
    for memory in all_results:
        if memory.temperature >= 0.70:
            promote_to_hot(memory)
        elif memory.temperature < 0.50:
            demote_from_hot(memory)

    # 4. Return sorted by temperature
    return sorted(all_results, key=lambda m: m.temperature)
```

---

<!-- _class: purple-bg -->
<!-- _backgroundColor: #6b21a8 -->
<!-- _color: #ffffff -->
<style scoped>
h1, h2, p, strong { color: #ffffff !important; }
h1 { border-bottom-color: #ffffff; }
</style>

# Section 6
## Pattern Graph System

---

# Pattern Graph Structure

```
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   ENTITIES     â”‚  Keywords from queries
         â”‚ deploy, docker â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ edges (strength-weighted)
                 â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   PATTERNS     â”‚  Trigger â†’ Strategy pairs
         â”‚ "How to deploy â”‚
         â”‚  â†’ Use docker  â”‚
         â”‚    compose..." â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Find patterns via keyword matching, not just embeddings!**

---

# Pattern Matching Algorithm

```python
def find_patterns(keywords):
    results = {}

    for keyword in keywords:
        if keyword in entity_to_patterns:
            for (pattern_id, strength) in entity_to_patterns[keyword]:
                score = strength Ã— pattern.effectiveness
                results[pattern_id] = max(existing, score)

    return sorted(results, key=score, reverse=True)
```

**Complexity**: O(k Ã— p) where k=keywords, p=patterns per keyword

---

# Pattern Relevance Scoring

```
relevance = 0.40 Ã— semantic_similarity
          + 0.15 Ã— keyword_overlap
          + 0.20 Ã— topic_overlap
          + 0.10 Ã— structure_match
          + 0.15 Ã— keyword_boost
```

| Signal | What It Captures |
|--------|------------------|
| Semantic | Embedding cosine similarity |
| Keyword | Jaccard of extracted keywords |
| Topic | Long words (â‰¥5 chars) overlap |
| Structure | Question pattern match ("how to" vs "what is") |

---

<!-- _class: purple-bg -->
<!-- _backgroundColor: #6b21a8 -->
<!-- _color: #ffffff -->
<style scoped>
h1, h2, p, strong { color: #ffffff !important; }
h1 { border-bottom-color: #ffffff; }
</style>

# Section 7
## Mode Selection

---

# Four Response Modes

| Mode | When | Cost | Latency |
|------|------|------|---------|
| **FAST** | Have memories | Low | <500ms |
| **AGENT** | Need exploration | Medium | 1-10s |
| **PATTERN_DIRECT** | High-confidence match | Very Low | <100ms |
| **WORKFLOW** | Complex multi-step | High | 10s+ |

---

# Mode Selection Algorithm

```python
def select_mode(query, memories, patterns):
    # Priority 1: Complex task keywords
    if "analyze" in query or "workflow" in query:
        return WORKFLOW

    # Priority 2: High-confidence pattern
    if patterns and best_pattern.relevance >= 0.7:
        return PATTERN_DIRECT  # Skip LLM!

    # Priority 3: Have memories
    if len(memories) >= 1:
        return FAST

    # Default: Need exploration
    return AGENT
```

---

<!-- _class: purple-bg -->
<!-- _backgroundColor: #6b21a8 -->
<!-- _color: #ffffff -->
<style scoped>
h1, h2, p, strong { color: #ffffff !important; }
h1 { border-bottom-color: #ffffff; }
</style>

# Section 8
## LLM-Driven Orchestration

---

# Why LLM-Driven Decisions?

**Rule-based limitations:**
- Fixed thresholds (temp > 0.7 â†’ promote)
- Keyword matching only
- Binary decisions
- Can't handle novel situations

**LLM-driven advantages:**
- Contextual reasoning ("this is relevant because...")
- Semantic understanding
- Nuanced confidence
- Generalizes to new contexts

---

# Orchestrator Flow

```
Query â†’ Initial Retrieval â†’ LLM Analysis â†’ Adjusted Decisions
              â”‚                  â”‚
              â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   â”‚  â€¢ Evaluate memory relevance â”‚
              â”‚   â”‚  â€¢ Suggest temp adjustments  â”‚
              â”‚   â”‚  â€¢ Extract keywords          â”‚
              â”‚   â”‚  â€¢ Recommend mode            â”‚
              â”‚   â”‚  â€¢ Provide reasoning         â”‚
              â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚                  â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â†’ Response
```

---

# Temperature Adjustment Formula

```python
# Combines rule-based (60%) with LLM judgment (40%)
adjusted_temp = (
    0.6 * rule_based_temperature +
    0.4 * llm_relevance_score +
    llm_suggested_adjustment
)
```

**LLM provides:**
- Relevance score (0.0-1.0)
- Reasoning ("Directly addresses deployment question")
- Adjustment suggestion (-0.3 to +0.3)

---

# LLM Provider Abstraction

```python
class BaseLLM(ABC):
    def complete(self, prompt: str, system: str = "") -> str: ...

# Available implementations
llm = get_llm("auto")  # Tries OpenAI â†’ Anthropic â†’ Mock

# Or specify explicitly
llm = get_llm("openai")    # GPT-4o-mini
llm = get_llm("anthropic") # Claude 3.5 Haiku
llm = get_llm("mock")      # No API needed (for workshop)
```

---

<!-- _class: purple-bg -->
<!-- _backgroundColor: #6b21a8 -->
<!-- _color: #ffffff -->
<style scoped>
h1, h2, p, strong { color: #ffffff !important; }
h1 { border-bottom-color: #ffffff; }
</style>

# The Complete Pipeline

---

# End-to-End Flow

```
1. KEYWORD EXTRACTION
   "How do I deploy Python?" â†’ ["deploy", "python"]

2. PATTERN GRAPH LOOKUP
   Keywords â†’ Pattern matches with relevance

3. MEMORY RECALL (Agentic RAG)
   Query embedding â†’ Tier search â†’ Promotions

4. PATTERN SCORING
   Multi-factor weighted scoring

5. LLM ORCHESTRATION
   Analyze + adjust + select mode

6. MODE SELECTION
   FAST / AGENT / PATTERN_DIRECT / WORKFLOW

7. RESPONSE GENERATION
```

---

# HGM vs Traditional RAG

| Aspect | Traditional RAG | HGM |
|--------|-----------------|-----|
| Retrieval | Static vector search | Dynamic three-tier |
| Organization | Fixed indexes | Self-organizing |
| Learning | None | Pattern graph |
| Routing | Always LLM | Mode selection |
| Context | Global | Per-agent focus |
| Decisions | Rule-based | LLM-enhanced |

---

<!-- _class: purple-bg -->
<!-- _backgroundColor: #6b21a8 -->
<style scoped>
h1, h2, p, strong { color: #ffffff !important; }
h1 { border-bottom-color: #ffffff; }
</style>

# Agent Chat Continuity

---

# How Hot Memory + Patterns Enable Continuity

**The Problem**: Each LLM call is stateless. How do agents maintain coherent conversations?

**The Solution**: Store messages with **labels** and reconstruct context from **hot memories + patterns**.

### Memory Labels

| Label | What It Stores | Purpose |
|-------|----------------|---------|
| `USER_QUERY` | User's exact message | Track what user asked |
| `AGENT_THOUGHT` | Agent's reasoning/response | Track decisions made |
| `PATTERN` | Learned strategy reference | Apply known solutions |

---

# Context Assembly with Labels

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AGENT CONTEXT WINDOW                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [SYSTEM PROMPT]                                             â”‚
â”‚  [HOT MEMORIES]                                              â”‚
â”‚     â€¢ [USER_QUERY] "Deploy my Python app"                   â”‚
â”‚     â€¢ [AGENT_THOUGHT] "User needs containerization"         â”‚
â”‚     â€¢ [USER_QUERY] "Use Kubernetes"                         â”‚
â”‚     â€¢ [AGENT_THOUGHT] "Switching to K8s approach"           â”‚
â”‚  [MATCHED PATTERNS]                                          â”‚
â”‚     â€¢ [PATTERN] kubernetes_deployment â†’ k8s manifest        â”‚
â”‚  [CURRENT EPISODE] Topic: deployment, Entities: k8s, python â”‚
â”‚  [USER MESSAGE] Current query                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Turn-Based Continuity Flow

```
TURN 1: User â†’ "Help me deploy my app"
   â”Œâ”€ STORE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  [USER_QUERY] "Help me deploy my app"               â”‚
   â”‚  [AGENT_THOUGHT] "User needs deployment guidance"   â”‚
   â”‚  [PATTERN] deployment â†’ docker_strategy             â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   Agent â†’ "I'll help you deploy using Docker..."

TURN 2: User â†’ "Use Kubernetes instead"
   â”Œâ”€ RECALL from HOT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  [USER_QUERY] "Help me deploy my app"  â† Turn 1     â”‚
   â”‚  [AGENT_THOUGHT] "User needs deployment guidance"   â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”Œâ”€ STORE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  [USER_QUERY] "Use Kubernetes instead"              â”‚
   â”‚  [AGENT_THOUGHT] "Switching to K8s approach"        â”‚
   â”‚  [PATTERN] kubernetes â†’ k8s_manifest_strategy       â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   Agent â†’ "For Kubernetes, create a deployment.yaml..."
```

---

# Successive Messages Without Breaking Context

```
TURN 3: User â†’ "What about secrets?"  (no explicit K8s mention)
   â”Œâ”€ RECALL from HOT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  [USER_QUERY] "Use Kubernetes instead"  â† Turn 2    â”‚
   â”‚  [AGENT_THOUGHT] "Switching to K8s approach"        â”‚
   â”‚  [PATTERN] kubernetes â†’ active context              â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   Agent KNOWS: "secrets" refers to Kubernetes secrets!
   Agent â†’ "For K8s secrets, use kubectl create secret..."

TURN 4: User â†’ "And ConfigMaps?"  (builds on previous)
   â”Œâ”€ RECALL from HOT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  All previous context + secrets discussion          â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   Agent â†’ "ConfigMaps work similarly to secrets..."
```

**Key**: Labels preserve context type, enabling intelligent recall.

---

# The Continuity Formula with Labels

**Context Assembly** for each turn:

```python
class MemoryLabel(str, Enum):
    USER_QUERY = "user_query"      # User's message
    AGENT_THOUGHT = "agent_thought" # Agent's reasoning
    PATTERN = "pattern"             # Matched strategy

def assemble_context(query: str) -> list[str]:
    context = []

    # 1. Hot memories with labels (sorted by temperature)
    hot_memories = hot_tier.scan(query_embedding, limit=10)
    for mem in hot_memories:
        context.append(f"[{mem.label}] {mem.content}")

    # 2. Matched patterns
    patterns = pattern_graph.find_patterns(keywords)
    for p in patterns:
        if p.relevance > 0.5:
            context.append(f"[PATTERN] {p.trigger}: {p.strategy}")

    return context
```

---

# Why Labels Enable Continuity

| Label | Role | Example |
|-------|------|---------|
| `USER_QUERY` | Track what user asked | "Deploy my app" â†’ "Use K8s" â†’ "secrets?" |
| `AGENT_THOUGHT` | Track agent decisions | "User needs containerization" |
| `PATTERN` | Apply learned strategies | "kubernetes â†’ use manifests" |

**How successive messages work:**
1. Each turn stores `[USER_QUERY]` + `[AGENT_THOUGHT]`
2. Next turn recalls previous labels from hot tier
3. Agent sees conversation history with context types
4. Ambiguous messages ("secrets?") resolved via recent `[PATTERN]`

**Result**: User can send short follow-ups without repeating context.

---

# Continuity Across Sessions

**Within session**: Hot tier maintains working memory

**Across sessions**: Patterns + Cold tier provide persistence

```
Session 1: Learn user prefers kubectl over helm
           â†’ Store in COLD, create pattern

Session 2: User asks about deployment
           â†’ Pattern match: "User prefers kubectl"
           â†’ Agent remembers preference!
```

---

<!-- _class: purple-bg -->
<!-- _backgroundColor: #6b21a8 -->
<style scoped>
h1, h2, p, strong { color: #ffffff !important; }
h1 { border-bottom-color: #ffffff; }
</style>

# Hands-On Exercises

---

# Exercise 1: Temperature Tuning

**Goal**: Understand how weights affect scoring

```python
# Try different weight configurations
recency_heavy = TemperatureConfig(weight_recency=0.50, ...)
relevance_heavy = TemperatureConfig(weight_relevance=0.55, ...)

# Compare results on same memory
```

**Question**: When would you prefer recency over relevance?

---

# Exercise 2: Pattern Creation

**Goal**: Add domain-specific patterns

```python
graph.add_pattern(
    "pat_kubernetes",
    "How to deploy to Kubernetes?",
    "Use kubectl apply or helm install",
    effectiveness=0.85,
)

# Link keywords
for kw in ["kubernetes", "k8s", "kubectl", "helm"]:
    graph.link_entity_to_pattern(kw, "pat_kubernetes")
```

**Test**: Query with "k8s deployment" - does your pattern match?

---

# Exercise 3: Mode Selector Enhancement

**Goal**: Add a CLARIFICATION mode

```python
class EnhancedModeSelector(ModeSelector):
    def _is_ambiguous(self, query: str) -> bool:
        # Very short queries
        if len(query.split()) <= 2:
            return True
        # No topic keywords
        if len(extract_keywords(query)) == 0:
            return True
        return False
```

**When should CLARIFICATION trigger?**

---

<!-- _class: purple-bg -->
<!-- _backgroundColor: #6b21a8 -->
<!-- _color: #ffffff -->
<style scoped>
h1, h2, p, strong { color: #ffffff !important; }
h1 { border-bottom-color: #ffffff; }
</style>

# Knowledge Check

---

# Quiz: Test Your Understanding

**Q1**: What are the 5 factors in the temperature formula?
<details>
<summary>Answer</summary>
Recency (30%), Frequency (15%), Relevance (35%), Entity Overlap (15%), Agent Match (5%)
</details>

**Q2**: When should a memory be promoted from Cold to Hot tier?
<details>
<summary>Answer</summary>
When its temperature reaches â‰¥ 0.70
</details>

**Q3**: What's the difference between SEMANTIC and EPISODIC memory?
<details>
<summary>Answer</summary>
SEMANTIC = facts/concepts ("Python is dynamically typed"), EPISODIC = events/experiences ("We discussed auth yesterday")
</details>

---

# Brain Teasers

**Scenario 1**: A user asks "How do I deploy?" but you have memories about Docker, Kubernetes, AND Heroku deployments. How does HGM decide which to surface?

**Think about**: Entity overlap, recent access patterns, agent focus

**Scenario 2**: An agent has been discussing Python for 10 turns, then user asks "What about types?" Should the system assume Python types or general type theory?

**Think about**: Episode tracking, focus embedding, context continuity

---

<!-- _class: purple-bg -->
<!-- _backgroundColor: #6b21a8 -->
<!-- _color: #ffffff -->
<style scoped>
h1, h2, p, strong { color: #ffffff !important; }
h1 { border-bottom-color: #ffffff; }
</style>

# Real-World Applications

---

# Industry Use Cases

| Industry | Application | HGM Benefit |
|----------|-------------|-------------|
| **Customer Service** | Support chatbots | Remember user history, preferences |
| **Healthcare** | Clinical assistants | Track patient context across sessions |
| **Finance** | Trading copilots | Recall relevant market patterns |
| **Legal** | Contract analysis | Maintain case context, precedents |
| **DevOps** | Incident response | Learn from past resolutions |

---

# Production Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Load Balancer                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   API Gateway                                â”‚
â”‚              (Auth, Rate Limiting)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              HGM Orchestration Service                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ Hot Tierâ”‚  â”‚Warm Tierâ”‚  â”‚Cold Tierâ”‚  â”‚ Pattern â”‚        â”‚
â”‚  â”‚ (Rust)  â”‚  â”‚ (Redis) â”‚  â”‚(Postgres)â”‚  â”‚  Graph  â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   LLM Provider                               â”‚
â”‚           (OpenAI / Anthropic / Local)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Real-World Scenario: Support Bot

```
Turn 1: User: "My payment failed"
        â†’ Store: [USER_QUERY] + [AGENT_THOUGHT: payment issue]
        â†’ Pattern match: payment_troubleshooting

Turn 2: User: "I'm using a Visa card"
        â†’ Recall: Previous payment context (HOT)
        â†’ Update focus: payment + visa + card
        â†’ Promote: visa_specific_errors pattern

Turn 3: User: "It says 'declined'"
        â†’ Full context: payment + visa + declined
        â†’ High-confidence pattern: card_declined_resolution
        â†’ Mode: PATTERN_DIRECT (skip LLM reasoning)
```

---

<!-- _class: purple-bg -->
<!-- _backgroundColor: #6b21a8 -->
<!-- _color: #ffffff -->
<style scoped>
h1, h2, p, strong { color: #ffffff !important; }
h1 { border-bottom-color: #ffffff; }
</style>

# Practice Projects

---

# Project 1: Personal Knowledge Assistant

**Goal**: Build a CLI assistant that remembers your notes

**Requirements**:
- Store notes with automatic memory type classification
- Recall relevant notes based on queries
- Track which notes you access frequently
- Implement basic temperature scoring

**Starter Code**: `projects/knowledge-assistant/`

**Deliverable**: Working CLI that persists memories across sessions

---

# Project 2: Code Review Memory

**Goal**: Agent that learns from past code reviews

**Requirements**:
- Parse PR comments and store as memories
- Build pattern graph of common issues â†’ fixes
- When reviewing new code, suggest based on past patterns
- Track which suggestions get accepted (feedback loop)

**Challenge**: Implement effectiveness scoring for patterns

**Deliverable**: GitHub Action or CLI tool

---

# Project Assignments

| Project | Difficulty | Time | Skills Practiced |
|---------|------------|------|------------------|
| Knowledge Assistant | â­â­ | 4-6 hrs | Memory types, temperature, recall |
| Code Review Memory | â­â­â­ | 8-12 hrs | Pattern graph, mode selection |
| Multi-Agent Chat | â­â­â­â­ | 12-16 hrs | Agent context, episode management |
| Production RAG | â­â­â­â­â­ | 20+ hrs | Full architecture, deployment |

**Submission**: Push to GitHub, tag `@darmie` for review

---

<!-- _class: purple-bg -->
<!-- _backgroundColor: #6b21a8 -->
<!-- _color: #ffffff -->
<style scoped>
h1, h2, p, strong { color: #ffffff !important; }
h1 { border-bottom-color: #ffffff; }
</style>

# State of the Art & Future

---

# Vendors & Production Solutions

| Vendor | Product | Key Feature |
|--------|---------|-------------|
| **Mem0** | mem0.ai | Managed memory layer for LLM apps |
| **Zep** | Zep Cloud | Long-term memory with temporal awareness |
| **LangChain** | LangMem | Memory persistence for LangGraph agents |
| **Pinecone** | Serverless | Vector DB with metadata filtering |
| **Weaviate** | Hybrid Search | Vector + keyword search, multi-tenancy |
| **Qdrant** | Qdrant Cloud | High-performance vector similarity |
| **Chroma** | ChromaDB | Open-source embedding database |
| **MongoDB** | Atlas Vector | Native vector search in MongoDB |

---

# Current Trends (2025)

| Trend | Description | Impact |
|-------|-------------|--------|
| **Longer Contexts** | 1M+ token windows (Gemini, Claude) | Less need for retrieval, but cost â†‘ |
| **Structured Outputs** | Native JSON mode, tool use | Better pattern matching |
| **Multi-Modal Memory** | Images, audio, video in context | Richer memory types |
| **Agent Frameworks** | LangGraph, CrewAI, AutoGen | Standardized memory interfaces |
| **Edge Deployment** | Local LLMs (Ollama, llama.cpp) | Privacy-first memory systems |

---

# Future Predictions

**2025-2026:**
- Memory systems become first-class framework features
- Standardized memory interchange formats emerge
- Real-time memory streaming for live agents

**2027+:**
- Persistent agent identities with lifelong memory
- Cross-agent memory sharing protocols
- Memory as a service (MaaS) platforms
- Neuromorphic memory hardware acceleration

**Key Insight**: Context engineering will be as fundamental as database design

---

# Further Reading

**Advanced Topics:**
- [A Survey on Large Language Model based Autonomous Agents](https://arxiv.org/abs/2308.11432)
- [Cognitive Architectures for Language Agents](https://arxiv.org/abs/2309.02427)
- [Tool Learning with Foundation Models](https://arxiv.org/abs/2304.08354)

**Implementation:**
- LangChain Memory modules
- LlamaIndex storage contexts
- Haystack document stores

**Communities:**
- r/LocalLLaMA, r/MachineLearning
- AI Discord servers
- HuggingFace forums

---

<!-- _class: purple-bg -->
<!-- _backgroundColor: #6b21a8 -->
<!-- _color: #ffffff -->
<style scoped>
h1, h2, p, strong { color: #ffffff !important; }
h1 { border-bottom-color: #ffffff; }
</style>

# Key Takeaways

---

# Core Concepts Recap

| Concept | Key Algorithm |
|---------|---------------|
| Memory Types | Cognitive classification |
| Agent State | Focus tracking + episodes |
| Temperature | 5-factor weighted scoring |
| Hot Tier | Token-budget LRU |
| Agentic RAG | Parallel search + promotion |
| Pattern Graph | Entity â†’ Pattern traversal |
| Pattern Scoring | Multi-signal combination |
| Mode Selection | Priority-based routing |
| LLM Orchestration | Reasoning-enhanced decisions |

---

# The Key Formulas

**Temperature:**
```
temp = 0.30Ã—recency + 0.15Ã—frequency + 0.35Ã—relevance
     + 0.15Ã—entity_overlap + 0.05Ã—agent_match
```

**Pattern Relevance:**
```
rel = 0.40Ã—semantic + 0.15Ã—keyword + 0.20Ã—topic
    + 0.10Ã—structure + 0.15Ã—boost
```

**LLM Temperature Adjustment:**
```
adjusted = 0.6Ã—rule_based + 0.4Ã—llm_relevance + adjustment
```

---

# Resources

**Workshop Materials:**
- Notebook: `workshops/hgm-core-concepts.ipynb`
- Slides: `workshops/hgm-core-concepts-slides.md`

**Research Papers:**
- [Generative Agents](https://arxiv.org/abs/2304.03442)
- [MemGPT](https://arxiv.org/abs/2310.08560)
- [Reflexion](https://arxiv.org/abs/2303.11366)
- [RAPTOR](https://arxiv.org/abs/2401.18059)

**Documentation:**
- [LangChain](https://docs.langchain.com)
- [LlamaIndex](https://docs.llamaindex.ai)

---

<!-- _class: purple-bg -->
<!-- _backgroundColor: #6b21a8 -->
<!-- _color: #ffffff -->
<style scoped>
h1, h2, p, strong, a { color: #ffffff !important; }
h1 { border-bottom-color: #ffffff; }
</style>

# Thank You!

## Questions?

**HGM: Cognitive infrastructure for AI that learns.**

**Damilare Akinlaja**
<img src="https://cdn.simpleicons.org/github/white" width="20" height="20" style="vertical-align: middle;" /> [github.com/darmie](https://github.com/darmie) | <img src="https://cdn.simpleicons.org/x/white" width="18" height="18" style="vertical-align: middle;" /> [x.com/fourEyedWiz](https://x.com/fourEyedWiz)

---

# Appendix: Quick Reference

```python
# Create memory
memory = create_memory(content, MemoryType.SEMANTIC, "path/to/topic")

# Score temperature
temp = scorer.compute(memory, focus_embedding, focus_entities)

# Recall with promotion
memories, promotions = tiers.recall(query_emb, entities)

# Find patterns
patterns = graph.find_patterns(keywords)

# LLM orchestration
decision = orchestrator.orchestrate(query, memories, patterns)
```
